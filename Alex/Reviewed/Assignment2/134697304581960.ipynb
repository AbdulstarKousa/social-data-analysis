{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, FactorRange\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "data = pd.read_csv(\"Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\")  ##dataframe is a datatype\n",
    "df = data\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df.Date.dt.year\n",
    "df['Month'] = df.Date.dt.month\n",
    "df['Day'] = df.Date.dt.day\n",
    "df['Hour'] = pd.to_datetime(df['Time'])\n",
    "df['Hour'] = df.Hour.dt.hour\n",
    "\n",
    "focuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'DRIVING UNDER THE INFLUENCE', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUNKENNESS', 'DRUG/NARCOTIC', 'TRESPASS', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY', 'DISORDERLY CONDUCT'])"
   ]
  },
  {
   "source": [
    "## Part 1: Questions to text and lectures.\n",
    "\n",
    "A) Please answer my questions to the Segal and Heer paper we read during lecture 7 and 8.\n",
    "\n",
    "* What is the *Oxford English Dictionary's* defintion of a narrative?\n",
    "\n",
    "> a description of events, especially in a novel; the act, process or skill of telling a story\n",
    "\n",
    "* What is your favorite visualization among the examples in section 3? Explain why in a few words.\n",
    "\n",
    "> My favorite sample is *The Minnesota Employment Explorer*:\n",
    "> * It's friendly to users with Mouse-hover for details and animated transition.\n",
    "> * It include social interaction features.\n",
    "\n",
    "* What's the point of Figure 7?\n",
    "\n",
    "> It describes different patterns of Design Space Dimensions: (1) genre, (2) visual narrative tactics, and (3) narrative structure\n",
    "tactics.\n",
    "\n",
    "* Use Figure 7 to find the most common design choice within each category for the Visual narrative and Narrative structure (the categories within visual narrative are 'visual structuring', 'highlighting', etc).\n",
    "\n",
    "> The most common choice within each categories:\n",
    "> * Genre: Annotated Graph / Map\n",
    "> * Visual structure: Consistent Visual Platform\n",
    "> * Highlighting: Feature Distinction\n",
    "> * Transition Guidance: object Continuity\n",
    "> * Ordering: User Directed Path\n",
    "> * Interactivicity: Filtering / Selection / Search\n",
    "> * Messaging: Captions / Headlines\n",
    "\n",
    "* Check out Figure 8 and section 4.3. What is your favorite genre of narrative visualization? Why? What is your least favorite genre? Why?\n",
    "\n",
    "> * My favorite genre is Flow chart. It contains the whole process and details about a project, easy to understand.\n",
    "> * My least favorite genre is magazine. It's filled with words and hard to find the key points.\n",
    "\n",
    "B) Also please answer the questions to my talk on [explanatory data visualization](https://www.youtube.com/watch?v=yHKYMGwefso)\n",
    "\n",
    "* What are the three key elements to keep in mind when you design an explanatory visualization?\n",
    "\n",
    "> * Start with a question\n",
    "> * Allow exploration\n",
    "> * Know your readers\n",
    "\n",
    "* In the video I talk about (1) *overview first*,  (2) *zoom and filter*,  (3) *details on demand*. \n",
    "  - Go online and find a visualization that follows these principles (don't use one from the video). \n",
    "  - Explain how it does achieves (1)-(3). It might be useful to use screenshots to illustrate your explanation.\n",
    "\n",
    "> Example from https://data.sfgov.org/d/tmnf-yvry/visualization: a visualization for SF dataset.\n",
    "> * overview: It can select different Dimension like category for Overview.\n",
    "> * Zoom and filter: It can add some measures for filtering and display the timeline of different type of crimes.\n",
    "> * Details on demand: you can hover your mouse on the chart and it will show the details. \n",
    "\n",
    "* Explain in your own words: How is explanatory data analysis different from exploratory data analysis?\n",
    "\n",
    "> * Explanatory data analysis don't give the consequences directly, it encourages readers to find the patterns behind the data by show different forms of data.\n",
    "> * Exploratory data analysis try to present specific results to demonstrate some hypothesis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Random forest and weather\n",
    "\n",
    "The aim here is to recreate the work you did in Part 1-3 of the Week 7 lecture. I've phrased things differently relative to the exercise to make the purpose more clear. \n",
    "\n",
    "Part 2A: Random forest binary classification. \n",
    "* Using the and instructions and material from Week 7, build a *random forest* classifier to distinguish between two types (you choose) of crime using on spatio-temporal (where/when) features of data describing the two crimes. When you're done, you should be able to give the classifier a place and a time, and it should tell you which of the two  types of crime happened there.\n",
    "  - Explain about your choices for training/test data, features, and encoding. (You decide how to present your results, but here are some example topics to consider: Did you balance the training data? What are the pros/cons of balancing? Do you think your model is overfitting? Did you choose to do cross-validation? Which specific features did you end up using? Why? Which features (if any) did you one-hot encode? Why ... or why not?))\n",
    "  - Report accuracy. Discuss the model performance.\n",
    "  \n",
    "  \n",
    "Part 2B: Info from weather features.\n",
    "* Now add features from weather data to your random forest. \n",
    "  - Report accuracy. \n",
    "  - Discuss how the model performance changes relative to the version with no weather data.\n",
    "  - Discuss what you have learned about crime from including weather data in your model."
   ]
  },
  {
   "source": [
    "### Part 2A\n",
    "**crime type**: `BURGLARY or FRAUD`\n",
    "\n",
    "**feature**: \n",
    "\n",
    "* `DayOfWeek` \n",
    "* `PD District` \n",
    "* Hour of the day (1-24)\n",
    "* Month of the year (1-12)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\xh975_9h4qt8f\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4563: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df1 = df[(df[\"Category\"] == 'BURGLARY') | (df[\"Category\"] == 'FRAUD')]\n",
    "df1['Category'].replace('BURGLARY',0,inplace = True)\n",
    "df1['Category'].replace('FRAUD',1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "category = df1['Category']\n",
    "day_dum = pd.get_dummies(df1['DayOfWeek'])\n",
    "dist_dum = pd.get_dummies(df1['PdDistrict'])\n",
    "hour_dum = pd.get_dummies(df1['Hour'])\n",
    "month_dum = pd.get_dummies(df['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Category  Friday  Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  \\\n",
       "0         1       0       0         0       0         0        1          0   \n",
       "1         0       0       0         0       0         0        0          1   \n",
       "2         0       0       0         0       0         1        0          0   \n",
       "3         1       0       0         0       0         1        0          0   \n",
       "4         0       1       0         0       0         0        0          0   \n",
       "\n",
       "   BAYVIEW  CENTRAL  ...  3  4  5  6  7  8  9  10  11  12  \n",
       "0        0        0  ...  0  0  0  0  0  0  0   1   0   0  \n",
       "1        1        0  ...  0  0  0  0  0  0  0   0   0   0  \n",
       "2        0        0  ...  0  0  0  0  0  0  0   0   0   0  \n",
       "3        0        0  ...  0  1  0  0  0  0  0   0   0   0  \n",
       "4        0        0  ...  0  0  0  0  0  0  0   0   0   0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Friday</th>\n      <th>Monday</th>\n      <th>Saturday</th>\n      <th>Sunday</th>\n      <th>Thursday</th>\n      <th>Tuesday</th>\n      <th>Wednesday</th>\n      <th>BAYVIEW</th>\n      <th>CENTRAL</th>\n      <th>...</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 54 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "testData = pd.concat([category, day_dum, dist_dum, hour_dum, month_dum], axis=1,join='inner')\n",
    "testData = testData.reset_index(drop=True)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(testData['Category'])\n",
    "# Remove the labels from the features\n",
    "testData= testData.drop('Category', axis = 1)\n",
    "# Saving feature names for later use\n",
    "feature_list = list(testData.columns)\n",
    "# Convert to numpy array\n",
    "testData = np.array(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(testData, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features Shape: (99311, 53)\nTraining Labels Shape: (99311,)\nTesting Features Shape: (33104, 53)\nTesting Labels Shape: (33104,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, n_estimators=50, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 50, random_state = 42, max_depth=20)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error: 0.38 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: nan %.\n",
      "<ipython-input-12-f46941e48193>:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)\n",
      "<ipython-input-12-f46941e48193>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mape = 100 * (errors / test_labels)\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data visualization\n",
    "\n",
    "* Create the Bokeh visualization from Part 2 of the Week 8 Lecture, displayed in a beautiful `.gif` below. \n",
    "* Provide nice comments for your code. Don't just use the `# inline comments`, but the full Notebook markdown capabilities and explain what you're doing.\n"
   ]
  },
  {
   "source": [
    "1. **Choose Take the data for the period of 2010-2018 and group it by hour-of-the-day (see Week 2)**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df[(df.Year>2009) & (df.Year<2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.DataFrame(columns=focuscrimes)\n",
    "Count = df3.groupby('Category').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "focuscrimes = set(['WEAPON LAWS', 'PROSTITUTION', 'DRIVING UNDER THE INFLUENCE', 'ROBBERY', 'BURGLARY', 'ASSAULT', 'DRUNKENNESS', 'DRUG/NARCOTIC', 'TRESPASS', 'LARCENY/THEFT', 'VANDALISM', 'VEHICLE THEFT', 'STOLEN PROPERTY', 'DISORDERLY CONDUCT'])\n",
    "\n",
    "hour = set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])"
   ]
  },
  {
   "source": [
    "2. **Normalization for each type of data.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in focuscrimes:\n",
    "    series = df3[df3[\"Category\"] == x].groupby('Hour').size()\n",
    "    for y in hour:\n",
    "        count_hour = series[y]\n",
    "        count_total = Count[x]\n",
    "        num_df.loc[y,x] = count_hour / count_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   TRESPASS DISORDERLY CONDUCT    ROBBERY   BURGLARY DRUG/NARCOTIC  \\\n",
       "0  0.028392          0.0516698  0.0553368   0.040437     0.0346767   \n",
       "1  0.020475          0.0380172  0.0600345  0.0279466     0.0206792   \n",
       "2  0.025571          0.0323461  0.0603454  0.0316854     0.0167675   \n",
       "3  0.021294          0.0182735  0.0373748  0.0334816     0.0123906   \n",
       "4  0.016198          0.0151229  0.0234888  0.0298891    0.00919778   \n",
       "\n",
       "  LARCENY/THEFT WEAPON LAWS PROSTITUTION VEHICLE THEFT  VANDALISM  \\\n",
       "0     0.0394609   0.0546579     0.129965      0.035958  0.0544846   \n",
       "1      0.025276   0.0394889    0.0961672     0.0242048  0.0381853   \n",
       "2     0.0154519   0.0339654    0.0609756     0.0182584  0.0355455   \n",
       "3    0.00995488   0.0237428    0.0365854     0.0119927  0.0259071   \n",
       "4     0.0065595   0.0162407    0.0195122      0.010077  0.0177113   \n",
       "\n",
       "  STOLEN PROPERTY DRIVING UNDER THE INFLUENCE    ASSAULT DRUNKENNESS  \n",
       "0       0.0444687                    0.120321  0.0564271   0.0807255  \n",
       "1       0.0335561                    0.112002  0.0480985   0.0769384  \n",
       "2       0.0294639                   0.0989305   0.043706   0.0703608  \n",
       "3        0.023462                   0.0475342   0.023417   0.0269085  \n",
       "4       0.0200518                   0.0172311  0.0145655   0.0141519  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TRESPASS</th>\n      <th>DISORDERLY CONDUCT</th>\n      <th>ROBBERY</th>\n      <th>BURGLARY</th>\n      <th>DRUG/NARCOTIC</th>\n      <th>LARCENY/THEFT</th>\n      <th>WEAPON LAWS</th>\n      <th>PROSTITUTION</th>\n      <th>VEHICLE THEFT</th>\n      <th>VANDALISM</th>\n      <th>STOLEN PROPERTY</th>\n      <th>DRIVING UNDER THE INFLUENCE</th>\n      <th>ASSAULT</th>\n      <th>DRUNKENNESS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.028392</td>\n      <td>0.0516698</td>\n      <td>0.0553368</td>\n      <td>0.040437</td>\n      <td>0.0346767</td>\n      <td>0.0394609</td>\n      <td>0.0546579</td>\n      <td>0.129965</td>\n      <td>0.035958</td>\n      <td>0.0544846</td>\n      <td>0.0444687</td>\n      <td>0.120321</td>\n      <td>0.0564271</td>\n      <td>0.0807255</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.020475</td>\n      <td>0.0380172</td>\n      <td>0.0600345</td>\n      <td>0.0279466</td>\n      <td>0.0206792</td>\n      <td>0.025276</td>\n      <td>0.0394889</td>\n      <td>0.0961672</td>\n      <td>0.0242048</td>\n      <td>0.0381853</td>\n      <td>0.0335561</td>\n      <td>0.112002</td>\n      <td>0.0480985</td>\n      <td>0.0769384</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.025571</td>\n      <td>0.0323461</td>\n      <td>0.0603454</td>\n      <td>0.0316854</td>\n      <td>0.0167675</td>\n      <td>0.0154519</td>\n      <td>0.0339654</td>\n      <td>0.0609756</td>\n      <td>0.0182584</td>\n      <td>0.0355455</td>\n      <td>0.0294639</td>\n      <td>0.0989305</td>\n      <td>0.043706</td>\n      <td>0.0703608</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.021294</td>\n      <td>0.0182735</td>\n      <td>0.0373748</td>\n      <td>0.0334816</td>\n      <td>0.0123906</td>\n      <td>0.00995488</td>\n      <td>0.0237428</td>\n      <td>0.0365854</td>\n      <td>0.0119927</td>\n      <td>0.0259071</td>\n      <td>0.023462</td>\n      <td>0.0475342</td>\n      <td>0.023417</td>\n      <td>0.0269085</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.016198</td>\n      <td>0.0151229</td>\n      <td>0.0234888</td>\n      <td>0.0298891</td>\n      <td>0.00919778</td>\n      <td>0.0065595</td>\n      <td>0.0162407</td>\n      <td>0.0195122</td>\n      <td>0.010077</td>\n      <td>0.0177113</td>\n      <td>0.0200518</td>\n      <td>0.0172311</td>\n      <td>0.0145655</td>\n      <td>0.0141519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "source": [
    "3. **convert Pandas Dataframe to Bokeh ColumnDataSource**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to bokeh\n",
    "src = ColumnDataSource(num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "p = figure(x_range = FactorRange(factors=hours),plot_height=250, toolbar_location=None, title=\"Crime Counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar ={} \n",
    "\n",
    "focuscrime = ['DRIVING UNDER THE INFLUENCE', 'ROBBERY', 'WEAPON LAWS', 'TRESPASS', 'STOLEN PROPERTY', 'DRUG/NARCOTIC', 'DISORDERLY CONDUCT', 'BURGLARY', 'DRUNKENNESS', 'VANDALISM', 'LARCENY/THEFT', 'VEHICLE THEFT', 'PROSTITUTION', 'ASSAULT']\n",
    "for indx,i in enumerate(focuscrime):\n",
    "    bar[i] = p.vbar(x='hours', top=i, source= src, legend_label=i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1038, glyph=VBar(id='1036', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1053, glyph=VBar(id='1051', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1067, glyph=VBar(id='1065', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1081, glyph=VBar(id='1079', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1095, glyph=VBar(id='1093', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1109, glyph=VBar(id='1107', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1123, glyph=VBar(id='1121', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1137, glyph=VBar(id='1135', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1151, glyph=VBar(id='1149', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1165, glyph=VBar(id='1163', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1179, glyph=VBar(id='1177', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1193, glyph=VBar(id='1191', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1207, glyph=VBar(id='1205', ...), ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"x\" value \"hours\" [renderer: GlyphRenderer(id=1221, glyph=VBar(id='1219', ...), ...)]\n"
     ]
    }
   ],
   "source": [
    "p.legend.click_policy=\"mute\" \n",
    "show(p) #displays your plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd053e53f6b1405538bcf995fe4851393b8a675c29f7728d8120f91d32ac1d11c5f",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}