{"cells":[{"source":["  ---\n","\n","  \n"," # <span style=\"color:MediumSlateBlue     \">Final Project | Explainer Notebook.</span>\n","\n"," ## <span style=\"color:MediumSlateBlue     \">Part 01 - Data Preprocessing.</span>\n","\n","\n","<span style=\"color:MediumSlateBlue     \">**02806 Social data analysis and visualization**</span>\n","\n","<span style=\"color:MediumSlateBlue     \">**May 2021**</span>\n","\n","<span style=\"color:MediumSlateBlue     \"> **Data-sets Reference: Motor-Vihecle-Collisions<sup>[link](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95)</sup>, Weather-Data<sup>[link](https://www.ncdc.noaa.gov/cdo-web/search)</sup>, Speed-Limit-Data<sup>[link](https://data.cityofnewyork.us/Transportation/VZV_Speed-Limits/7n5j-865y)**</sup></span>\n","\n","  ---\n","  \n","\n","  \n","<span style=\"color:Orange\">**Please note!**</span> If you are using Jupyter to display this \".ipynb\" file You might need to make it *Trusted* in order to let Jupyter render the plots.\n","   "],"cell_type":"markdown","metadata":{}},{"cell_type":"markdown","metadata":{},"source":["\n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Import needed libraries:</span>\n","\n","---\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\"\"\" IPython \"\"\"\n","from IPython.display import display\n","from IPython import get_ipython\n","get_ipython().run_line_magic('matplotlib', 'inline')\n","\n","\"\"\" Data Handeling \"\"\"\n","import numpy as np \n","import pandas as pd \n","import calendar\n","import os \n","from scipy import stats\n","\n","\"\"\" for warnings \"\"\"\n","import warnings \n","warnings.simplefilter(\"ignore\")"]},{"cell_type":"markdown","metadata":{},"source":["\n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Load data:</span>\n","\n","---\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\"\"\" Path \"\"\"\n","fileName = 'Motor_Vehicle_Collisions.csv'\n","filePath = os.path.abspath(os.path.join(os.getcwd(), fileName))\n","\n","\"\"\" Load \"\"\"\n","Data =  pd.read_csv(filePath);"]},{"cell_type":"markdown","metadata":{},"source":["\n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Getting to know the Dataset:</span>\n","\n","---\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\"\"\" Define a function to track Reduction in data when doing the data prepration and cleaning later on \"\"\"\n","\n","Reduction = {}\n","Reduction_Percentage = {}\n","N = Data.shape[0]\n","def reduc(step):\n","    global N \n","    global Reduction\n","    global Reduction_Percentage\n","    N_before = N\n","    N_after = Data.shape[0]\n","    Reduction[step] = N_after\n","    Reduction_Percentage[step] = (N_before - N_after) / N_before\n","    print(f'Number of observation: {N_after}  (--{N_before-N_after})')\n","    print(f'Reduction: {N_before - N_after}  ({(N_before - N_after) / N_before} %)')\n","    N = Data.shape[0]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of observation: 1769702  (--0)\nReduction: 0  (0.0 %)\n"]}],"source":["\"\"\" Initilize Reduction in data \"\"\"\n","reduc('Init')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   CRASH DATE CRASH TIME        BOROUGH ZIP CODE   LATITUDE  LONGITUDE  \\\n","0  10/18/2020      20:00       BROOKLYN    11210  40.630295 -73.947450   \n","1  11/26/2020       3:06            NaN      NaN        NaN        NaN   \n","2  11/05/2020      19:40  STATEN ISLAND    10310  40.630276 -74.107956   \n","3  12/02/2020       8:00         QUEENS    11414  40.660072 -73.845650   \n","4  10/19/2020       1:55          BRONX    10468        NaN        NaN   \n","\n","                  LOCATION                    ON STREET NAME  \\\n","0   (40.630295, -73.94745)                               NaN   \n","1                      NaN  CROSS BAY BOULEVARD                \n","2  (40.630276, -74.107956)                               NaN   \n","3   (40.660072, -73.84565)                               NaN   \n","4                      NaN  UNIVERSITY HEIGHTS BRIDGE          \n","\n","   CROSS STREET NAME                           OFF STREET NAME  ...  \\\n","0                NaN  2236      NOSTRAND AVENUE                 ...   \n","1      SHORE PARKWAY                                       NaN  ...   \n","2                NaN  532       FOREST AVENUE                   ...   \n","3                NaN  87-14     158 AVENUE                      ...   \n","4  WEST FORDHAM ROAD                                       NaN  ...   \n","\n","    CONTRIBUTING FACTOR VEHICLE 2  CONTRIBUTING FACTOR VEHICLE 3  \\\n","0                             NaN                            NaN   \n","1  Driver Inattention/Distraction                            NaN   \n","2                     Unspecified                            NaN   \n","3                     Unspecified                            NaN   \n","4                             NaN                            NaN   \n","\n","   CONTRIBUTING FACTOR VEHICLE 4  CONTRIBUTING FACTOR VEHICLE 5  COLLISION_ID  \\\n","0                            NaN                            NaN       4359260   \n","1                            NaN                            NaN       4370998   \n","2                            NaN                            NaN       4365813   \n","3                            NaN                            NaN       4372508   \n","4                            NaN                            NaN       4359179   \n","\n","                   VEHICLE TYPE CODE 1                  VEHICLE TYPE CODE 2  \\\n","0  Station Wagon/Sport Utility Vehicle                                  NaN   \n","1                                Sedan                                Sedan   \n","2                                Sedan  Station Wagon/Sport Utility Vehicle   \n","3  Station Wagon/Sport Utility Vehicle  Station Wagon/Sport Utility Vehicle   \n","4  Station Wagon/Sport Utility Vehicle                                  NaN   \n","\n","   VEHICLE TYPE CODE 3 VEHICLE TYPE CODE 4 VEHICLE TYPE CODE 5  \n","0                  NaN                 NaN                 NaN  \n","1                  NaN                 NaN                 NaN  \n","2                  NaN                 NaN                 NaN  \n","3                  NaN                 NaN                 NaN  \n","4                  NaN                 NaN                 NaN  \n","\n","[5 rows x 29 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRASH DATE</th>\n      <th>CRASH TIME</th>\n      <th>BOROUGH</th>\n      <th>ZIP CODE</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LOCATION</th>\n      <th>ON STREET NAME</th>\n      <th>CROSS STREET NAME</th>\n      <th>OFF STREET NAME</th>\n      <th>...</th>\n      <th>CONTRIBUTING FACTOR VEHICLE 2</th>\n      <th>CONTRIBUTING FACTOR VEHICLE 3</th>\n      <th>CONTRIBUTING FACTOR VEHICLE 4</th>\n      <th>CONTRIBUTING FACTOR VEHICLE 5</th>\n      <th>COLLISION_ID</th>\n      <th>VEHICLE TYPE CODE 1</th>\n      <th>VEHICLE TYPE CODE 2</th>\n      <th>VEHICLE TYPE CODE 3</th>\n      <th>VEHICLE TYPE CODE 4</th>\n      <th>VEHICLE TYPE CODE 5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>10/18/2020</td>\n      <td>20:00</td>\n      <td>BROOKLYN</td>\n      <td>11210</td>\n      <td>40.630295</td>\n      <td>-73.947450</td>\n      <td>(40.630295, -73.94745)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2236      NOSTRAND AVENUE</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4359260</td>\n      <td>Station Wagon/Sport Utility Vehicle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>11/26/2020</td>\n      <td>3:06</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>CROSS BAY BOULEVARD</td>\n      <td>SHORE PARKWAY</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>Driver Inattention/Distraction</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4370998</td>\n      <td>Sedan</td>\n      <td>Sedan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>11/05/2020</td>\n      <td>19:40</td>\n      <td>STATEN ISLAND</td>\n      <td>10310</td>\n      <td>40.630276</td>\n      <td>-74.107956</td>\n      <td>(40.630276, -74.107956)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>532       FOREST AVENUE</td>\n      <td>...</td>\n      <td>Unspecified</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4365813</td>\n      <td>Sedan</td>\n      <td>Station Wagon/Sport Utility Vehicle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>12/02/2020</td>\n      <td>8:00</td>\n      <td>QUEENS</td>\n      <td>11414</td>\n      <td>40.660072</td>\n      <td>-73.845650</td>\n      <td>(40.660072, -73.84565)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87-14     158 AVENUE</td>\n      <td>...</td>\n      <td>Unspecified</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4372508</td>\n      <td>Station Wagon/Sport Utility Vehicle</td>\n      <td>Station Wagon/Sport Utility Vehicle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>10/19/2020</td>\n      <td>1:55</td>\n      <td>BRONX</td>\n      <td>10468</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>UNIVERSITY HEIGHTS BRIDGE</td>\n      <td>WEST FORDHAM ROAD</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4359179</td>\n      <td>Station Wagon/Sport Utility Vehicle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"},"metadata":{},"execution_count":5}],"source":["\"\"\" Overview \"\"\"\n","Data.head(n=5)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1769702, 29)"]},"metadata":{},"execution_count":6}],"source":["\"\"\" Data shape \"\"\"\n","Data.shape"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n","       'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME',\n","       'OFF STREET NAME', 'NUMBER OF PERSONS INJURED',\n","       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n","       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n","       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n","       'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1',\n","       'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n","       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5',\n","       'COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2',\n","       'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}],"source":["\"\"\" Columns' names \"\"\"\n","Data.columns"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CRASH DATE                        object\n","CRASH TIME                        object\n","BOROUGH                           object\n","ZIP CODE                          object\n","LATITUDE                         float64\n","LONGITUDE                        float64\n","LOCATION                          object\n","ON STREET NAME                    object\n","CROSS STREET NAME                 object\n","OFF STREET NAME                   object\n","NUMBER OF PERSONS INJURED        float64\n","NUMBER OF PERSONS KILLED         float64\n","NUMBER OF PEDESTRIANS INJURED      int64\n","NUMBER OF PEDESTRIANS KILLED       int64\n","NUMBER OF CYCLIST INJURED          int64\n","NUMBER OF CYCLIST KILLED           int64\n","NUMBER OF MOTORIST INJURED         int64\n","NUMBER OF MOTORIST KILLED          int64\n","CONTRIBUTING FACTOR VEHICLE 1     object\n","CONTRIBUTING FACTOR VEHICLE 2     object\n","CONTRIBUTING FACTOR VEHICLE 3     object\n","CONTRIBUTING FACTOR VEHICLE 4     object\n","CONTRIBUTING FACTOR VEHICLE 5     object\n","COLLISION_ID                       int64\n","VEHICLE TYPE CODE 1               object\n","VEHICLE TYPE CODE 2               object\n","VEHICLE TYPE CODE 3               object\n","VEHICLE TYPE CODE 4               object\n","VEHICLE TYPE CODE 5               object\n","dtype: object"]},"metadata":{},"execution_count":8}],"source":["\"\"\" Columns types \"\"\"\n","Data.dtypes"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('VEHICLE TYPE CODE 5', 1763172),\n"," ('CONTRIBUTING FACTOR VEHICLE 5', 1762996),\n"," ('VEHICLE TYPE CODE 4', 1744800),\n"," ('CONTRIBUTING FACTOR VEHICLE 4', 1744084),\n"," ('VEHICLE TYPE CODE 3', 1654119),\n"," ('CONTRIBUTING FACTOR VEHICLE 3', 1650864),\n"," ('OFF STREET NAME', 1504966),\n"," ('CROSS STREET NAME', 623675),\n"," ('ZIP CODE', 544174),\n"," ('BOROUGH', 543962),\n"," ('ON STREET NAME', 357104),\n"," ('VEHICLE TYPE CODE 2', 293896),\n"," ('CONTRIBUTING FACTOR VEHICLE 2', 251078),\n"," ('LATITUDE', 209365),\n"," ('LONGITUDE', 209365),\n"," ('LOCATION', 209365),\n"," ('VEHICLE TYPE CODE 1', 9355),\n"," ('CONTRIBUTING FACTOR VEHICLE 1', 4987),\n"," ('NUMBER OF PERSONS KILLED', 31),\n"," ('NUMBER OF PERSONS INJURED', 18),\n"," ('CRASH DATE', 0),\n"," ('CRASH TIME', 0),\n"," ('NUMBER OF PEDESTRIANS INJURED', 0),\n"," ('NUMBER OF PEDESTRIANS KILLED', 0),\n"," ('NUMBER OF CYCLIST INJURED', 0),\n"," ('NUMBER OF CYCLIST KILLED', 0),\n"," ('NUMBER OF MOTORIST INJURED', 0),\n"," ('NUMBER OF MOTORIST KILLED', 0),\n"," ('COLLISION_ID', 0)]"]},"metadata":{},"execution_count":9}],"source":["\"\"\" Count columns' NaN values in desending order \"\"\"\n","sorted(list(zip(Data.columns,Data.isna().sum(axis=0).values)) , key= lambda row: row[1], reverse=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('CRASH DATE', 1769702),\n"," ('CRASH TIME', 1769702),\n"," ('NUMBER OF PEDESTRIANS INJURED', 1769702),\n"," ('NUMBER OF PEDESTRIANS KILLED', 1769702),\n"," ('NUMBER OF CYCLIST INJURED', 1769702),\n"," ('NUMBER OF CYCLIST KILLED', 1769702),\n"," ('NUMBER OF MOTORIST INJURED', 1769702),\n"," ('NUMBER OF MOTORIST KILLED', 1769702),\n"," ('COLLISION_ID', 1769702),\n"," ('NUMBER OF PERSONS INJURED', 1769684),\n"," ('NUMBER OF PERSONS KILLED', 1769671),\n"," ('CONTRIBUTING FACTOR VEHICLE 1', 1764715),\n"," ('VEHICLE TYPE CODE 1', 1760347),\n"," ('LATITUDE', 1560337),\n"," ('LONGITUDE', 1560337),\n"," ('LOCATION', 1560337),\n"," ('CONTRIBUTING FACTOR VEHICLE 2', 1518624),\n"," ('VEHICLE TYPE CODE 2', 1475806),\n"," ('ON STREET NAME', 1412598),\n"," ('BOROUGH', 1225740),\n"," ('ZIP CODE', 1225528),\n"," ('CROSS STREET NAME', 1146027),\n"," ('OFF STREET NAME', 264736),\n"," ('CONTRIBUTING FACTOR VEHICLE 3', 118838),\n"," ('VEHICLE TYPE CODE 3', 115583),\n"," ('CONTRIBUTING FACTOR VEHICLE 4', 25618),\n"," ('VEHICLE TYPE CODE 4', 24902),\n"," ('CONTRIBUTING FACTOR VEHICLE 5', 6706),\n"," ('VEHICLE TYPE CODE 5', 6530)]"]},"metadata":{},"execution_count":10}],"source":["\"\"\" Count columns' Non-NaN values in desending order \"\"\"\n","sorted(list(zip(Data.count().keys(),Data.count().values)), key= lambda row: row[1], reverse=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CRASH DATE                             0\n","CRASH TIME                             0\n","BOROUGH                                0\n","ZIP CODE                               0\n","LATITUDE                            1766\n","LONGITUDE                           1766\n","LOCATION                               0\n","ON STREET NAME                         0\n","CROSS STREET NAME                      0\n","OFF STREET NAME                        0\n","NUMBER OF PERSONS INJURED        1414110\n","NUMBER OF PERSONS KILLED         1767530\n","NUMBER OF PEDESTRIANS INJURED    1682257\n","NUMBER OF PEDESTRIANS KILLED     1768543\n","NUMBER OF CYCLIST INJURED        1729563\n","NUMBER OF CYCLIST KILLED         1769535\n","NUMBER OF MOTORIST INJURED       1540017\n","NUMBER OF MOTORIST KILLED        1768883\n","CONTRIBUTING FACTOR VEHICLE 1          0\n","CONTRIBUTING FACTOR VEHICLE 2          0\n","CONTRIBUTING FACTOR VEHICLE 3          0\n","CONTRIBUTING FACTOR VEHICLE 4          0\n","CONTRIBUTING FACTOR VEHICLE 5          0\n","COLLISION_ID                           0\n","VEHICLE TYPE CODE 1                    0\n","VEHICLE TYPE CODE 2                    0\n","VEHICLE TYPE CODE 3                    0\n","VEHICLE TYPE CODE 4                    0\n","VEHICLE TYPE CODE 5                    0\n","dtype: int64"]},"metadata":{},"execution_count":11}],"source":["\"\"\" Count columns' zeros values \"\"\"\n","(Data == 0).sum(axis=0)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CRASH DATE                       0\n","CRASH TIME                       0\n","BOROUGH                          0\n","ZIP CODE                         0\n","LATITUDE                         0\n","LONGITUDE                        0\n","LOCATION                         0\n","ON STREET NAME                   0\n","CROSS STREET NAME                0\n","OFF STREET NAME                  0\n","NUMBER OF PERSONS INJURED        0\n","NUMBER OF PERSONS KILLED         0\n","NUMBER OF PEDESTRIANS INJURED    0\n","NUMBER OF PEDESTRIANS KILLED     0\n","NUMBER OF CYCLIST INJURED        0\n","NUMBER OF CYCLIST KILLED         0\n","NUMBER OF MOTORIST INJURED       0\n","NUMBER OF MOTORIST KILLED        0\n","CONTRIBUTING FACTOR VEHICLE 1    0\n","CONTRIBUTING FACTOR VEHICLE 2    0\n","CONTRIBUTING FACTOR VEHICLE 3    0\n","CONTRIBUTING FACTOR VEHICLE 4    0\n","CONTRIBUTING FACTOR VEHICLE 5    0\n","COLLISION_ID                     0\n","VEHICLE TYPE CODE 1              0\n","VEHICLE TYPE CODE 2              0\n","VEHICLE TYPE CODE 3              0\n","VEHICLE TYPE CODE 4              0\n","VEHICLE TYPE CODE 5              0\n","dtype: int64"]},"metadata":{},"execution_count":12}],"source":["\"\"\" Count columns' empty strings \"\"\"\n","(Data == '').sum(axis=0)"]},{"cell_type":"markdown","metadata":{},"source":[" \n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Data Cleaning:</span>\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["## Drop unneeded features:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of observation: 1763247  (--6455)\nReduction: 6455  (0.0036475067553746335 %)\n"]}],"source":["\"\"\" Drop 'COLLISION_ID' since it's not informative \"\"\"\n","Data = Data.drop(columns=['COLLISION_ID'])\n","\n","\"\"\" Drop 'LOCATION' since we have 'LATITUDE', 'LONGITUDE' \"\"\"\n","Data = Data.drop(columns=['LOCATION'])\n","\n","\"\"\" Drop 'CROSS STREET NAME' and 'OFF STREET NAME' since we have 'ON STREET NAME' \"\"\"\n","Data = Data.drop(columns=['CROSS STREET NAME', 'OFF STREET NAME'])\n","\n","\"\"\" Drop PEDESTRIANS, CYCLIST and MOTORIST features since we have PERSONS features \"\"\"\n","Data = Data.drop(columns = ['NUMBER OF PEDESTRIANS INJURED','NUMBER OF PEDESTRIANS KILLED', \n","                            'NUMBER OF CYCLIST INJURED','NUMBER OF CYCLIST KILLED', \n","                            'NUMBER OF MOTORIST INJURED','NUMBER OF MOTORIST KILLED'])\n","\n","\"\"\" Consider only Collisions with two vehicles involve and Drop other unrelated features \"\"\"\n","Data = Data[\n","        (Data['CONTRIBUTING FACTOR VEHICLE 3'].isna())|\n","        (Data['CONTRIBUTING FACTOR VEHICLE 4'].isna())|\n","        (Data['CONTRIBUTING FACTOR VEHICLE 5'].isna())|\n","        (Data['VEHICLE TYPE CODE 3'].isna())|\n","        (Data['VEHICLE TYPE CODE 4'].isna())|\n","        (Data['VEHICLE TYPE CODE 5'].isna())]\n","Data = Data.drop(columns=['CONTRIBUTING FACTOR VEHICLE 3','CONTRIBUTING FACTOR VEHICLE 4','CONTRIBUTING FACTOR VEHICLE 5','VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'])\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('MVC with only two vehicles involves')"]},{"cell_type":"markdown","metadata":{},"source":[" \n","---\n","\n","## <span style=\"color:MediumSlateBlue\">Missing Data:</span>\n","\n","---"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of observation: 1250921  (--512326)\nReduction: 512326  (0.290558271189459 %)\n"]}],"source":["\"\"\" Count columns' NaN values in desending order \"\"\"\n","sorted(list(zip(Data.columns,Data.isna().sum(axis=0).values)) , key= lambda row: row[1], reverse=True)\n","\n","\"\"\" Count columns' zeros values \"\"\"\n","(Data == 0).sum(axis=0)\n","\n","\"\"\" Count columns' empty strings \"\"\"\n","(Data == '').sum(axis=0)\n","\n","\"\"\" Drop rows that has a messing value in one of important features \"\"\"\n","Data = Data[\n","    Data['ON STREET NAME'].notna()  & # important feature for adding speed limit data later on.\n","    Data['LATITUDE' ].notna()       & # imporatnt feature for map plots \n","    Data['LONGITUDE'].notna()       & # imporatnt feature for map plots\n","    Data['NUMBER OF PERSONS INJURED'].notna()   & # imporatnt feature since one of the main features of intress\n","    Data['NUMBER OF PERSONS KILLED'].notna()      # imporatnt feature since one of the main features of intress\n","    ].copy()\n","\n","\"\"\" Drop raws with LATITUDE or LONGITUDE = 0 \"\"\"\n","Data = Data[(Data['LATITUDE']!=0)|(Data['LONGITUDE']!=0)].copy()\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Drop missing values in important features')"]},{"cell_type":"markdown","metadata":{},"source":[" \n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Features Prepration:</span>\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Vehicle types:"]},{"cell_type":"markdown","metadata":{},"source":[" **Prepare Vehicle type 1:**"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Vehicles Type 1 (95 % Frequent):\n['sport utility vehicle', 'sedan', 'passenger vehicle', 'taxi', 'pick-up truck', 'van', 'bus', 'unknown', 'other', 'box truck', 'small com veh(4 tires)']\n\n"]}],"source":["\"\"\" Unify Vehicle type recording way \"\"\"\n","Data['VEHICLE TYPE CODE 1'] = Data['VEHICLE TYPE CODE 1'].str.lower()\n","Data['VEHICLE TYPE CODE 1'] = Data['VEHICLE TYPE CODE 1'].str.strip()\n","\n","\"\"\" Fixing recording issus of Vehicle types that has more than 50 MVC occurrences \"\"\"\n","Frequent_MVC_Vehicles = (Data['VEHICLE TYPE CODE 1'].value_counts().keys()[Data['VEHICLE TYPE CODE 1'].value_counts().values > 50])\n","\n","Mapping = { # Basesd on Frequent_MVC_Vehicles values\n","    np.nan: 'unknown',\n","    'station wagon/sport utility vehicle': 'sport utility vehicle', \n","    'sport utility / station wagon':'sport utility vehicle', \n","    '4 dr sedan': 'sedan', \n","    'ambul': 'ambulance',  \n","    'school bus': 'school bus', \n","    'e-sco': 'e-scooter', \n","    'schoo': 'school bus', \n","    'bicycle': 'bike'\n","    }\n","\n","Data['VEHICLE TYPE CODE 1'] = Data['VEHICLE TYPE CODE 1'].replace(Mapping)\n","\n","\"\"\" Consider only 95 % Frequent MVC Vehicle types \"\"\"\n","VT1 = pd.DataFrame()\n","VT1['VEHICLE TYPE CODE 1'] = Data['VEHICLE TYPE CODE 1'].value_counts(normalize=True).keys()\n","VT1['Frequencies'] = Data['VEHICLE TYPE CODE 1'].value_counts(normalize=True).values\n","\n","threshold = 0\n","for i in range(len(VT1['VEHICLE TYPE CODE 1'].unique())):\n","    Sum = VT1['Frequencies'][0:i+1].sum()\n","    if Sum > 0.95:\n","         threshold = i + 1\n","        #  print(\"Threshold that covers 95% of \" + \"VEHICLE TYPEs\".lower() +  \" = \" + f\"{threshold}\")\n","         break \n","Focus_Vehicles_Type_1 = list(VT1['VEHICLE TYPE CODE 1'][0:threshold].values)\n","print('Focus Vehicles Type 1 (95 % Frequent):')\n","print(Focus_Vehicles_Type_1)\n","print()"]},{"cell_type":"markdown","metadata":{},"source":["**Prepare Vehicle type 2:**"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Vehicles Type 2 (95 % Frequent):\n['sport utility vehicle' 'unknown' 'sedan' 'passenger vehicle' 'taxi'\n 'bike' 'pick-up truck' 'van' 'bus' 'other' 'box truck']\n\n"]}],"source":["\"\"\" Unify Vehicle type recording way \"\"\"\n","Data['VEHICLE TYPE CODE 2'] = Data['VEHICLE TYPE CODE 2'].str.lower()\n","Data['VEHICLE TYPE CODE 2'] = Data['VEHICLE TYPE CODE 2'].str.strip()\n","\n","\"\"\" Fixing recording issus of Vehicle types that has more than 50 MVC occurrences \"\"\"\n","Frequent_MVC_Vehicles = (Data['VEHICLE TYPE CODE 2'].value_counts().keys()[Data['VEHICLE TYPE CODE 2'].value_counts().values > 50])\n","\n","Mapping = { # Based on Frequent_MVC_Vehicles values\n","    np.nan: 'unknown',\n","    'unkno': 'unknown',\n","    'unk': 'unknown',\n","    'station wagon/sport utility vehicle': 'sport utility vehicle', \n","    'sport utility / station wagon':'sport utility vehicle', \n","    '4 dr sedan': 'sedan', \n","    'ambul': 'ambulance',  \n","    'school bus': 'school bus', \n","    'e-sco': 'e-scooter', \n","    'schoo': 'school bus', \n","    'bicycle': 'bike', \n","    }\n","\n","Data['VEHICLE TYPE CODE 2'] = Data['VEHICLE TYPE CODE 2'].replace(Mapping)\n","\n","\"\"\" Consider only 95 % Frequent MVC Vehicle types \"\"\"\n","VT2 = pd.DataFrame()\n","VT2['VEHICLE TYPE CODE 2'] = Data['VEHICLE TYPE CODE 2'].value_counts(normalize=True).keys()\n","VT2['Frequencies'] = Data['VEHICLE TYPE CODE 2'].value_counts(normalize=True).values\n","\n","threshold = 0\n","for i in range(len(VT2['VEHICLE TYPE CODE 2'].unique())):\n","    Sum = VT2['Frequencies'][0:i+1].sum()\n","    if Sum > 0.95:\n","         threshold = i + 1\n","        #  print(\"Threshold that cover 95% of \" + \"VEHICLE TYPEs\".lower() +  \" = \" + f\"{threshold}\")\n","         break \n","Focus_Vehicles_Type_2 = VT2['VEHICLE TYPE CODE 2'][0:threshold].values\n","\n","print('Focus Vehicles Type 2 (95 % Frequent):')\n","print(Focus_Vehicles_Type_2)\n","print()"]},{"cell_type":"markdown","metadata":{},"source":["**Slice Focus Vehicle Types (covers more than 95 % of MVC occurrences)**"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Vehicles ( More than 95 % Frequent):\n['other', 'passenger vehicle', 'bike', 'unknown', 'pick-up truck', 'box truck', 'small com veh(4 tires)', 'sedan', 'van', 'sport utility vehicle', 'bus', 'taxi']\n\nNumber of observation: 1150870  (--100051)\nReduction: 100051  (0.07998186935865655 %)\n"]}],"source":["\"\"\" Slice \"\"\"\n","Focus_Vehicle_Types = list(set(list(Focus_Vehicles_Type_1) + list(Focus_Vehicles_Type_2))) \n","Data = Data[Data['VEHICLE TYPE CODE 1'].isin((Focus_Vehicle_Types)) & (Data['VEHICLE TYPE CODE 2'].isin(Focus_Vehicle_Types))].copy()\n","print('Focus Vehicles ( More than 95 % Frequent):')\n","print(Focus_Vehicle_Types)\n","print()\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Slice Focus Vehicle Types')\n","\n","\"\"\" free memory \"\"\"\n","del(VT1,VT2)"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Contributing Factors:"]},{"cell_type":"markdown","metadata":{},"source":["**Prepare Contributing Factor 1:**"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Factors 1 (95 % Frequent):\n['unspecified', 'driver inattention/distraction', 'failure to yield right-of-way', 'following too closely', 'passing or lane usage improper', 'backing unsafely', 'other vehicular', 'turning improperly', 'fatigued/drowsy', 'unsafe lane changing', 'traffic control disregarded', 'driver inexperience', 'lost consciousness', 'reaction to uninvolved vehicle', 'unsafe speed', 'pavement slippery', 'prescription medication', 'alcohol involvement', 'physical disability', 'outside car distraction']\n\n"]}],"source":["\"\"\" Unify Contributing Factor string \"\"\"\n","Data['CONTRIBUTING FACTOR VEHICLE 1'] = Data['CONTRIBUTING FACTOR VEHICLE 1'].str.lower()\n","Data['CONTRIBUTING FACTOR VEHICLE 1'] = Data['CONTRIBUTING FACTOR VEHICLE 1'].str.strip()\n","\n","\"\"\" Fixing recording issus of Contributing Factor that has more than 50 MVC occurrences \"\"\"\n","Frequent_MVC_Factors = (Data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().keys()[Data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().values > 50])\n","\n","Mapping = { # Based on Frequent_MVC_Factors\n","    np.nan: 'unknown',\n","    'illnes':'illness', \n","    'reaction to other uninvolved vehicle':'reaction to uninvolved vehicle',\n","    'passing too closely': 'passing or lane usage improper',\n","    }\n","\n","Data['CONTRIBUTING FACTOR VEHICLE 1'] = Data['CONTRIBUTING FACTOR VEHICLE 1'].replace(Mapping)\n","\n","\"\"\" Consider only 95 % Frequent MVC Contributing Factors \"\"\"\n","CF1 = pd.DataFrame()\n","CF1['CONTRIBUTING FACTOR VEHICLE 1'] = Data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts(normalize=True).keys()\n","CF1['Frequencies'] = Data['CONTRIBUTING FACTOR VEHICLE 1'].value_counts(normalize=True).values\n","\n","threshold = 0\n","for i in range(len(CF1['CONTRIBUTING FACTOR VEHICLE 1'].unique())):\n","    Sum = CF1['Frequencies'][0:i+1].sum()\n","    if Sum > 0.95:\n","         threshold = i + 1\n","        #  print(\"Threshold that covers 95% of \" + \"CONTRIBUTING FACTORs\".lower() +  \" = \" + f\"{threshold}\")\n","         break \n","Focus_Factors_Type_1 = list(CF1['CONTRIBUTING FACTOR VEHICLE 1'][0:threshold].values)\n","print('Focus Factors 1 (95 % Frequent):')\n","print(Focus_Factors_Type_1)\n","print()"]},{"cell_type":"markdown","metadata":{},"source":["**Prepare Contributing Factor 2:**"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Factors 2 (95 % Frequent):\n['unspecified', 'unknown', 'driver inattention/distraction', 'other vehicular', 'passing or lane usage improper', 'failure to yield right-of-way', 'following too closely']\n\n"]}],"source":["\"\"\" Unify Contributing Factor string \"\"\"\n","Data['CONTRIBUTING FACTOR VEHICLE 2'] = Data['CONTRIBUTING FACTOR VEHICLE 2'].str.lower()\n","Data['CONTRIBUTING FACTOR VEHICLE 2'] = Data['CONTRIBUTING FACTOR VEHICLE 2'].str.strip()\n","\n","\"\"\" Fixing recording issus of Contributing Factor that has more than 50 MVC occurrences \"\"\"\n","Frequent_MVC_Factors = (Data['CONTRIBUTING FACTOR VEHICLE 2'].value_counts().keys()[Data['CONTRIBUTING FACTOR VEHICLE 2'].value_counts().values > 50])\n","\n","Mapping = { # Based on Frequent_MVC_Factors\n","    np.nan: 'unknown',\n","    'illnes':'illness', \n","    'reaction to other uninvolved vehicle':'reaction to uninvolved vehicle',\n","    'passing too closely': 'passing or lane usage improper',\n","    }\n","\n","Data['CONTRIBUTING FACTOR VEHICLE 2'] = Data['CONTRIBUTING FACTOR VEHICLE 2'].replace(Mapping)\n","\n","\"\"\" Consider only 95 % Frequent MVC Contributing Factors \"\"\"\n","CF2 = pd.DataFrame()\n","CF2['CONTRIBUTING FACTOR VEHICLE 2'] = Data['CONTRIBUTING FACTOR VEHICLE 2'].value_counts(normalize=True).keys()\n","CF2['Frequencies'] = Data['CONTRIBUTING FACTOR VEHICLE 2'].value_counts(normalize=True).values\n","\n","threshold = 0\n","for i in range(len(CF2['CONTRIBUTING FACTOR VEHICLE 2'].unique())):\n","    Sum = CF2['Frequencies'][0:i+1].sum()\n","    if Sum > 0.95:\n","         threshold = i + 1\n","        #  print(\"Threshold that covers 95% of \" + \"CONTRIBUTING FACTORs\".lower() +  \" = \" + f\"{threshold}\")\n","         break \n","Focus_Factors_Type_2 = list(CF2['CONTRIBUTING FACTOR VEHICLE 2'][0:threshold].values)\n","print('Focus Factors 2 (95 % Frequent):')\n","print(Focus_Factors_Type_2)\n","print()"]},{"cell_type":"markdown","metadata":{},"source":["**Slice Focus Factors Type (covers more than 95 % of MVC occurrences)**"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Focus Factors ( More than 95 % Frequent):\n['driver inattention/distraction', 'passing or lane usage improper', 'unsafe speed', 'other vehicular', 'fatigued/drowsy', 'turning improperly', 'pavement slippery', 'lost consciousness', 'alcohol involvement', 'physical disability', 'reaction to uninvolved vehicle', 'backing unsafely', 'traffic control disregarded', 'driver inexperience', 'unspecified', 'failure to yield right-of-way', 'following too closely', 'unknown', 'unsafe lane changing', 'outside car distraction', 'prescription medication']\n\nNumber of observation: 1096004  (--54866)\nReduction: 54866  (0.04767349917888206 %)\n"]}],"source":["\"\"\" Slice \"\"\"\n","Focus_Factors_Types = list(set(list(Focus_Factors_Type_1) + list(Focus_Factors_Type_2))) \n","Data = Data[Data['CONTRIBUTING FACTOR VEHICLE 1'].isin((Focus_Factors_Types)) & (Data['CONTRIBUTING FACTOR VEHICLE 2'].isin(Focus_Factors_Types))].copy()\n","print('Focus Factors ( More than 95 % Frequent):')\n","print(Focus_Factors_Types)\n","print()\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Slice Focus Factors Types')\n","\n","\"\"\" free memory \"\"\"\n","del(CF1,CF2)"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Zip Features:"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["\"\"\" Drop Unspecified Zip \"\"\"\n","Data['ZIP CODE'].replace(to_replace='     ', value=np.nan, inplace=True)\n","\n","\"\"\" Change the Zip type to float64 \"\"\" \n","Data['ZIP CODE'] = pd.to_numeric(Data['ZIP CODE']) "]},{"cell_type":"markdown","metadata":{},"source":[" ##  Extract new feutres:"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["\"\"\" Add the 'Respone' feature, which is a binary future that says 0 if there is no injures or killed person and 1 other wise. \"\"\"\n","Data['Response'] = Data[['NUMBER OF PERSONS INJURED','NUMBER OF PERSONS KILLED']].sum(axis=1)\n","Data['Response'] = Data['Response'].apply(lambda y: 1 if y > 0 else 0)\n","\n","\"\"\" Add 'Year' feature \"\"\"\n","Data['Year']    = pd.to_datetime(Data['CRASH DATE']).dt.year\n","\n","\"\"\" Add 'Month' feature \"\"\"\n","Data['Month']    = pd.to_datetime(Data['CRASH DATE']).dt.month\n","\n","\"\"\" Add 'Day' feature \"\"\"\n","Data['Day'] = pd.to_datetime(Data['CRASH DATE']).dt.day\n","\n","\"\"\" 'Day of week' feature \"\"\"\n","Data['Day of week'] = pd.to_datetime(Data['CRASH DATE']).dt.day_name()\n","\n","\"\"\" Add 'Hour' feature \"\"\"\n","Data['Hour'] = pd.to_datetime(Data['CRASH TIME']).dt.hour\n","\n","\"\"\" Add 'Minute' feature \"\"\"\n","Data['Minute'] = pd.to_datetime(Data['CRASH TIME']).dt.minute"]},{"cell_type":"markdown","metadata":{},"source":["## Drop uncompleted years:"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of observation: 1014071  (--81933)\nReduction: 81933  (0.07475611402878092 %)\n"]}],"source":["\"\"\" Drop rows from 2012 since they are not completed  \"\"\"\n","Data = Data[Data['Year']!=2012]\n","\n","\"\"\" Drop rows from 2021 since they are not completed  \"\"\"\n","Data = Data[Data['Year']!=2021]\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Drop uncompleted years')"]},{"cell_type":"markdown","metadata":{},"source":[" \n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Adding new Datasets:</span>\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["## Adding Speed_Limits Mode Data:"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Merging Speed Limits:\n","    Number of Matched Streets = 5994\n","    Number of Unmatched Streets = 1357\n","Number of observation: 958371  (--55700)\n","Reduction: 55700  (0.05492712048761872 %)\n"]}],"source":["\"\"\" path \"\"\"\n","fileName = 'dot_VZV_Speed_Limits_20210507.csv'\n","filePath = os.path.abspath(os.path.join(os.getcwd(), fileName))\n","\n","\"\"\" load \"\"\"\n","speed_limits =  pd.read_csv(filePath)\n","\n","\"\"\" Drop speed limits rows with missing values in important features \"\"\"\n","speed_limits = speed_limits[\n","        speed_limits['street'].notna()  &\n","        speed_limits['postvz_sl'].notna()  \n","    ].copy()\n","\n","\"\"\" Prepare street name features of both datasets for merging \"\"\"\n","Data.loc[:,'ON STREET NAME'] = Data['ON STREET NAME'].str.lower()\n","Data.loc[:,'ON STREET NAME'] = Data['ON STREET NAME'].str.strip()\n","speed_limits.loc[:,'street'] = speed_limits['street'].str.lower()\n","speed_limits.loc[:,'street'] = speed_limits['street'].str.strip()\n","\n","Matched_streets = Data['ON STREET NAME'][Data['ON STREET NAME'].isin(speed_limits['street'])].unique()\n","print('Merging Speed Limits:') \n","print(f\"    Number of Matched Streets = {len(Matched_streets)}\")\n","print(f\"    Number of Unmatched Streets = {len(Data['ON STREET NAME'].unique()) - len(Matched_streets)}\")\n","\n","\"\"\" Calculate speed limits mode\"\"\"\n","Street_Speed_Mode = {}\n","streets = speed_limits['street'].unique()\n","for street in streets:\n","    Street_Values = speed_limits[speed_limits['street']==street]['postvz_sl']\n","    Street_Mode = stats.mode(Street_Values)[0][0]\n","    Street_Speed_Mode[street]= Street_Mode\n","\n","\"\"\" Add speed limits mode to Data \"\"\"\n","Data = Data[Data['ON STREET NAME'].isin(streets)].copy()\n","Data['SPEED LIMIT MODE'] = Data['ON STREET NAME'].apply(lambda street: Street_Speed_Mode[street])\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Adding Speed_Limits')\n","\n","\"\"\" Free memory \"\"\"\n","del(speed_limits,Matched_streets, Street_Speed_Mode, streets)"]},{"cell_type":"markdown","metadata":{},"source":[" ## Adding weather data:"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of observation: 958371  (--0)\nReduction: 0  (0.0 %)\n"]}],"source":["\"\"\"\n","Attributes description:\n","    AWND : Average wind speed\n","\n","    TMAX : Maximum temperature\n","    TMIN : Minimum temperature\n","\n","    PRCP : Precipitation\n","    WT16 : Rain(may include freezing rain, drizzle, and freezing drizzle)\"\n","\n","    SNOW : Snowfall\n","    SNWD : Snow depth\n","    WT18 : Snow, snow pellets, snow grains, or ice crystals\n","\n","    WT08 : Smoke or haze\n","    WT22 : Ice fog or freezing fog\n","    WT01 : Fog, ice fog, or freezing fog (may include heavy fog)\n","    WT02 : Heavy fog or heaving freezing fog (not always distinguished from fog)\n","    WT13 : Mist\n","\n","    WT06 : Glaze or rime\n","\"\"\"\n","\n","\"\"\" Path \"\"\"\n","fileName = 'weather.csv'\n","filePath = os.path.abspath(os.path.join(os.getcwd(), fileName))\n","\n","\"\"\" Load \"\"\"\n","weather =  pd.read_csv(filePath)\n","\n","\"\"\" Slice needed features for further investigation \"\"\"\n","weather_features = (\n","    ['DATE'] + # date\n","    ['AWND'] + # wind related \n","    ['TMAX','TMIN'] + # temp related\n","    ['PRCP','WT16'] + # rain related\n","    ['SNOW','SNWD','WT18'] + # snow related\n","    ['WT08','WT22','WT01','WT02','WT13'] + # fog/vision related\n","    ['WT06'] # rime related\n","    )\n","weather = weather[weather_features]\n","weather = weather.fillna(0)\n","\n","\"\"\" prepare rain related features: \n","        PRCP : Precipitation\n","        WT16 : Rain(may include freezing rain, drizzle, and freezing drizzle)\"\n","\"\"\"\n","weather[['PRCP','WT16']]\n","weather['PRCP'].value_counts().values\n","weather['WT16'].value_counts() # 23 \n","\n","weather['Precipitation'.upper()] = weather['PRCP'].copy()\n","weather = weather.drop(columns=['PRCP','WT16'])\n","\n","weather['Precipitation'.upper()].value_counts()\n","\n","\n","\"\"\" prepare snow related features:\n","        SNOW : Snowfall\n","        SNWD : Snow depth\n","        WT18 : Snow, snow pellets, snow grains, or ice crystals\n","\"\"\"\n","weather[['SNOW','SNWD','WT18']]\n","weather['SNOW'].value_counts()\n","weather['SNWD'].value_counts()\n","weather['WT18'].value_counts() # 21\n","\n","weather['Snow fall'.upper()] = weather['SNOW'].copy()\n","weather['Snow depth'.upper()] = weather['SNWD'].copy()\n","weather = weather.drop(columns=['SNOW','SNWD','WT18'])\n","\n","weather['Snow fall'.upper()].value_counts()\n","weather['Snow depth'.upper()].value_counts()\n","\n","\n","\"\"\" prepare fog/vision related features:\n","        WT01 : Fog, ice fog, or freezing fog (may include heavy fog)\n","        WT08 : Smoke or haze\n","        WT02 : Heavy fog or heaving freezing fog (not always distinguished from fog)\n","        WT13 : Mist\n","        WT22 : Ice fog or freezing fog\n","\"\"\"\n","weather[['WT08','WT22','WT01','WT02','WT13']]\n","weather['WT01'].value_counts()\n","weather['WT08'].value_counts()\n","weather['WT02'].value_counts()\n","weather['WT13'].value_counts() # 27\n","weather['WT22'].value_counts() # 2\n","\n","weather['Fog, Smoke or haze'.upper()] = np.where(weather[['WT01','WT08','WT02']].sum(axis=1) == 0, 0, 1)\n","weather = weather.drop(columns=['WT08','WT22','WT01','WT02','WT13'])\n","\n","weather['Fog, Smoke or haze'.upper()].value_counts()\n","\n","\n","\"\"\" prepare rime related features \"\"\"\n","\"\"\"\n","    WT06 : Glaze or rime\n","\"\"\"\n","weather['WT06']\n","weather['WT06'].value_counts() # 14\n","weather = weather.drop(columns=['WT06'])\n","\n","\n","\"\"\" Merage weather data with Data \"\"\"\n","weather['DATE'] = pd.to_datetime(weather['DATE']).dt.date\n","Data['DATE'] = pd.to_datetime(Data['CRASH DATE']).dt.date\n","\n","Data = pd.merge(Data, weather, on='DATE', how='left')\n","Data = Data.drop(columns=['DATE'])\n","\n","\"\"\" Track Reduction in data \"\"\"\n","reduc('Adding Weather')\n","\n","\"\"\" View and Rename Weather features \"\"\"\n","Data['Average wind speed'.upper()] = Data['AWND'].copy()\n","Data['Maximum temperature'.upper()] = Data['TMAX'].copy()\n","Data['Minimum temperature'.upper()] = Data['TMIN'].copy()\n","Data = Data.drop(columns=['AWND','TMAX','TMIN'])\n","\n","\"\"\" free memory \"\"\"\n","del(weather)"]},{"cell_type":"markdown","metadata":{},"source":[" \n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Save final Data:</span>\n","\n","---\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["fileName = 'MVC_SL_W_Final.csv'\n","filePath = os.path.abspath(os.path.join(os.getcwd(), fileName))\n","Data.to_csv(filePath)"]},{"source":[" \n","---\n","\n","# <span style=\"color:MediumSlateBlue\">Clear All Variables:</span>\n","\n","---\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["%reset -f"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.7.4 64-bit ('base': conda)","metadata":{"interpreter":{"hash":"c1191167135d73a38360128be5b872cc1d98473796dd4629575553b5d0fe39f6"}}}}}